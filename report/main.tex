\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[
    backend=biber,
    style=apa,
    citestyle=authoryear
]{biblatex}
\setlength{\bibitemsep}{0.5em}
\addbibresource{references.bib}
\usepackage{parskip}
\usepackage{xcolor}

\title{Multi-core Synergy: A Study of Performance Improvements Utilizing Multi-core Threading}
\author{J. Wolffrom}
\date{\today}

\begin{document}

\maketitle
\newpage

\begin{abstract}

\end{abstract}
\newpage

\tableofcontents
\newpage

\section{Introduction}

According to Moore's Law, the number of transistors on a microchip doubles every two years, leading to an exponential increase in computing power. However, this trend has slowed down in recent years, as we are approaching the limitations of silicon based technology \parencite{Mattson2014}.

\begin{quote}
    \textit{\textcolor{darkgray}{Increased clock speeds meant higher heat generation and power consumption, necessitating more robust cooling solutions and improved power management techniques. The quest for ever-higher clock speeds eventually reached a plateau due to these limitations, leading to a shift in CPU design principles.}} - \parencite{mscodes} 
\end{quote}

As a result of the processing speed ceiling, the focus has shifted from increasing the clock speed of CPUs to adding more computational units to them. This has led to the rise of multi-core processors, which contain multiple processing units on a single chip, often referred to as "cores". These cores can execute multiple orders simultaneiously, which can lead to significant performance improvements in software applications. However, a discrepancy can be found in the communities that rely on these improvements.

\begin{quote}
    \textit{\textcolor{darkgray}{While there are some PC games that love CPUs with a dozen or more cores, theyâ€™re few and far between. 
    Instead, finding an 8-core, 16-thread processor with a high clock speed and a lot of L3 Cache is going to get you further than just adding more CPU cores to the equation. }} 
    - \parencite{Thomas2025}
\end{quote}

Within the gaming communities we're seeing a trend of diminishing returns, whereas what we should be seeing is an equivalance. There is a concensus that multi-core threading is the future of software development, and it has been for several years now, even as far back as 2005 \parencite{mscodes}, so the question is what's holding us back?

\subsection{The Problem Area}

If multi-core threading is the future, then it is essential to understand why it is not delivering the expected performance improvements it has the potential to deliver. \parencite[p. 12]{Rauber2023} mentions that simulations have shown that superscalar processors with up to four functional units yield substantial benefits over the use of a single functional unit. So in theory, it would seem there is a great potential to gain from utilizing multiple cores. Some of it has been utilized according to \textcite{Thomas2025}, as we are talking about 8-cores as opposed to one, but it has taken us well over 20 years to get to this point.

As such, this study aims to address this question of why multi-code optimization is so difficult to accomplish, if and/or how it can be improved, and what the potential benefits of doing so are. In addition, we wish to bring to light the concept of multi-core threading or processing as a whole, seeing as it has slipped out of the public's eye in recent years. Now, more than ever, with the rise of machine learning and AI, we need to be able to utilize the full potential of our hardware.

\subsubsection{Research Question}

This being said, there are limits to what can be achieved in such a short study, therefore we will be focusing heavily on the theory behind multi-core computing and how to get startet with it. 

The research question that we will be addressing is then as follows:

\begin{quote}
    \textit{What are the challenges of multi-core optimization, and how can they be overcome?}
\end{quote}

This question can then be further broken down into the following sub-questions:

\begin{itemize}
    \item What does the standard architecture of a CPU look like? Is there one?
    \item What is a thread, and what is a processor?
    \item What frameworks are commonly used for multi-core threading?
    \item What are the challenges of multi-core threading, and how can they be overcome?
\end{itemize}

These questions serve as a guide for the study and will help to structure the research process, beginning with a review of the literature on the topic.

\section{Limitations}

This study is limited in scope to just a handful of programming languages, and even in that case we will just be delving into the details of Python. This is due to the fact that Python isn't necessarily the best language in terms of performance, but is one of the slowest in terms of execution time. This makes python an exceptional candidate for multi-core threading, as it stands to gain the most from it.

As such, the primary focus will be the theory behind multi-core processing in python with a few examples of how to implement it. We will be looking at how languages such as C, Java, and C\# handle multi-core processing, but we will not be going into detail on how to implement it in those languages. The focus will be strictly on comparisons for the sake of understanding key concepts like parallelism and concurrency.

In addition to the limits of programming languages, we will also be limiting the range of operating systems to just Windows and Linux. This is due to the fact that these share the same range of common chipsets as opposed to MacOS, which keeps to a very small range of chipsets. This is not to say that MacOS is not capable of multi-core processing, but rather that most of the practical applications of multi-core processing are applied to Windows and Linux systems.

\section{Terminology}

For the purpose of this paper, we will be using a lot of terminology that refers to the different sub-components of a computer. We expect the reader to have a basic understanding of what a computer is, and a general overview of its components, such as knowing what a CPU is and what role it plays. 

The term \textbf{core} refers to a single processing unit that is housen within a CPU, which will occur frequently in this paper. The term \textbf{thread} and \textbf{process} are often used interchangeably when going over the CPU architecture, but threads are generally smaller and are often used to refer to single tasks of which a process could contain many. This is not to be confused with a \textbf{processor} which is a kind of processing unit that is smaller in size than a core, and is often used to refer to the physical chip that is used to execute the orders.

\section{Synchronous and Asynchronous systems}

When looking at computing with multi-core systems it is important to understand the difference between a synchronous and asynchronous system. In general, when we talk about systems that use a single processing unit we usually always talk of a synchronous system, as orders are executed in order. When we scale this order up to several processing units on the same chipset we have what is referred to as a multicore processor, which is the focal point of this study. This multicore processor can then either be synchronous in order to keep to the order of executions that computers are used to, or we can choose to make it asynchronous, allowing all processing units to execute somewhat independently of each other. 

The reality of synchronous and asynchronous systems is that they are not entirely separate. They are often used in conjunction with each other, as we need levels of synchronization in order to access shared resources between different cores. Simple tasks such as reading and writing to memory is determined by whether another core is using that memory at the same time, further complicating the matter.

\subsubsection{Subroutines and Coroutines}

In order to understand asynchronous systems, it's important to note both subroutines and coroutines. 

Subroutines are the standard way of executing tasks in traditional programming, where the order of execution is determined by the order of which commands are written in the code. These are often known as Functions in programming languages, and are executed in a inear fashion, exiting once they finish executing. This makes then quite similar to coroutines, as they share the same functionality, except for the the ability to suspend their execution, also known by the 'yield' and 'resume' keywords. 

This means that coroutines can be used to execute tasks in a non-linear fashion, allowing for more flexibility in the order of executions. Whether or not we have a coroutine defined as the target to 'yield' to also determines whether we are working with synchronous or asynchronous systems. 'yield'ing to a coroutine means that we are working with dependencies, pausing the execution of a program to wait for a result from another coroutine. 

For an example, look at the following python snippet:
\begin{verbatim}

import asyncio

async def main():
    print('Hello ...')
    await asyncio.sleep(1)
    print('... World!')

asyncio.run(main())
\end{verbatim}

Which defines an asynchronous main function, or a coroutime that will print "Hello World" interspaced by one second. This shows the prominent 'yield' functionality. If we gave the function a target to yield to, we would in turn make the code synchronous in nature.

\subsection{Threading}

The reason why subroutines and coroutines are important to understand is because they relate quite heavily to threads. 

Threading is a way of executing multiple different tasks at the same time in a computer operating system. Every program on a computer intrinsically define at least one thread of operations they want the operating system to execute. This is often referred to as the main thread, and is the thread that is executed first when a program is started, which can then spawn sub-threads to execute other tasks. The OS then handles what order threads are executed in using what is known as a "Scheduler", this scheduler is then also responsible for 'Suspending' threads to make it seem like all programs are executed concurrently. 

This process of suspending threads is what allows for the illusion of concurrency, allowing the operating system to seemingly execute multiple threads at the same time by switching back and forth rapidly between tasks. This is known as "context switching", and is a key feature of modern operating systems, making even a single core processing system capable of multi-tasking.

This is not to be confused with multi-core processing, which is the ability to execute multiple threads at the same time with different cores. This is where the real performance improvements come from, as we can execute multiple tasks at the same time without having to switch as often. This is known as "parallelism", and is a key feature of modern multi-core processors.

\section{Parallelism}
\subsection{Degree of Parallelism}
\subsubsection{Parallel Execution Time (PET)}

Consists of the time it takes for all cores or processors to finish a given program.

Also the time for data exchange or synchronization.

Should be smaller than the time for a synchronized single-core process to be worth it.

Influenced by idle times.

Smallest execution time occurs generally when workload is distributed equally amongst cores/processors.

Speedup and efficiency are used to quantitatively measure the parallel execution time.

\subsubsection{Load Balancing}

When the workload of a program is distributed equally amongst the machine's cores or processors.

\subsubsection{Idle Time}

The time a processor cannot do anything useful but wait for more work.

\section{Memory}
\subsection{Shared Memory}

Memory organization where the machine shares memory for all threads.

Synchronization plays a heavy role, for example by keeping threads from reading files before another has written to them.

Often connected to the term "Thread".

\subsection{Memory Access Time (MAT)}

Add content if applicable.

\section{Schedulers}

Add content if applicable.

\section{TRIN Model}

Add content if applicable.

\section{State of the Field}
\subsection{Python}

As it stands, Python is one of the most popular programming languages in the field of computer science. It is widely used in a variety of applications due to its simplicity and ease of use. However, it is an interpreted language, which means that it is not as fast as compiled languages like C or C++. In fact it is written in C, which is a compiled language. This means that in places it keeps the speed of C by pre-compiling certain commands, but in other places it is slower than C, with up to 10 times the execution in difference.

This is important due to the way Python handles multi-core threading. By default, Python comes pre-installed with threading and asynchronous libraries, which allow for the use of multiple threads in a program, however the presence of the Global Interpreter Lock (GIL) means that only one core will be in use at any time. This means that the performance improvements of multi-core threading are not easily accessed, but by using libraries such as 'multiprocessing' or 'numpy', we can bypass the GIL using some of the same utilities in C. This allows us to use multiple cores in a program, but it is not as easy to implement as it is in other languages.

\subsection{Java}

Java comes with a built-in threading library, which allows for the use of multiple threads in a program, managed by the Java Virtual Machine (JVM). Usually this is accomplished by inheritance, designating a class as a thread, allowing it to use common threading methods such as sleep (suspension) and join (synchronization). This means that Java is able to utilize multiple cores in a program by use of their own scheduler, and the performance improvements are easily accessible. However, this is not without its drawbacks, as the JVM is an interpreted language, which means that it is not as fast as compiled languages like C or C++. In addition, the JVM is not as efficient as other languages when it comes to memory management, which can lead to performance issues in large programs. 

\subsection{C\#}

C\# is a compiled language that is part of the C language family like Python, however where it differs is its striking resemblance to Java. It is a high-level language that is designed to be easy to use and understand, gathering a lot of attention due to its usage in the Unity game engine as well as developers transitioning from other languages. It is therefore a prime candidate for multi-core processing optimization as Java developers come potentially pre-equipped with a solid foundation of threading, as well as new game developers looking for performance improvements.

The way C\# handles multi-core threading is not the same as Java, as it provides a library to assign tasks to threads, which in turn are managed by the operating system's scheduler. This means that C\# is able to utilize multiple cores in a program, but it is not as easy to implement as it is in Java. However, C\# does have some advantages over Java when it comes to performance, as it is a compiled language and therefore faster than Java. In addition, C\# has a more efficient memory management system than Java, which can lead to performance improvements in large programs.

\subsection{C}

C, unlike the previous mentions, is a low-level programming language. It is a compiled language that is designed to be fast and efficient, making it a popular choice for system programming and embedded systems. C is often used in applications where performance is critical, such as operating systems, device drivers, and high-performance computing, as well as game engines. It is therefore a prime candidate for multi-core processing optimization, as wherever C is used in practice it is often done so with performance in mind.

C provides a library for multi-core threading called Posix, labeling their way of threading as 'pthreads' or 'POSIX threads'. This library is a standard for multi-core threading in C, and comes pre-installed with unix systems such as Linux in the GCC compiler used for this study.

\section{Data Collection}

Section on how the data was collected, what was collected and the code used. 

Potentially rename the section to something more fitting.

\section{Results}

Add content if applicable.

\section{Discussion}

Include thoughts about other programming languages.

\section{Conclusion}

Add content if applicable.

\newpage
\section{References}
\printbibliography
% Ensure Biber is run to resolve undefined references

\end{document}